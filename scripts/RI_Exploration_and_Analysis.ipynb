{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pyproj\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This notebook covers:\n",
    "# ðŸ“ˆ Data Acquisition, Cleaning, Predictor and Outcome Variable Creation ðŸ“‰\n",
    "Note this does not include anything realted to SST or Wind Shear, as they are given their own notebook ðŸ˜¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read in data from official HURDAT2.csv file\n",
    "\n",
    "Updated 10 June 2021 to include the 2020 hurricane season. These methods read in the raw HURDAT2 file, convert it to a lines object, and then to a dataframe. The method `hurdat_lines_to_df` adds the storm identifier to each row, as described in Note 1 at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hurdat_lines():\n",
    "    \"\"\"\n",
    "    read in official NHC HURDAT2.csv data file as line oject; \n",
    "    args: none; returns: line object\n",
    "    \"\"\"\n",
    "    f = open(\"../data/HURDAT2.csv\", \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hurdat_lines_to_df(lines):\n",
    "    \"\"\"\n",
    "    convert HURDAT lines object to dataframe, accounting for necessary formating of HURDAT data file, see note (1);\n",
    "    args: lines object; returns: df with all storm observations, in tidy format(?)\n",
    "    \"\"\"\n",
    "    hurdat = []     # to store all observations as nested list\n",
    "    storm_info = [] # to store name and storm code\n",
    "    df = pd.DataFrame()\n",
    "    for line in lines:\n",
    "        arr = line.split(\",\")\n",
    "        \n",
    "        # If this is a new storm, it will have \"AL\" in the first item ('AL' for Atlantic stroms)\n",
    "        # Since this is a new storm, we need to update storm info and not add this 'observation' to list\n",
    "        if \"AL\" in arr[0]: \n",
    "            storm_info = [arr[0],arr[1].strip()]\n",
    "            \n",
    "        # If this is the same storm as previous row, add new observation to list of others\n",
    "        else:\n",
    "            arr.insert(0,storm_info[0])\n",
    "            arr.insert(1,storm_info[1])\n",
    "            hurdat.append(arr)\n",
    "            \n",
    "    # Create and return dataframe from the nested list of observations\n",
    "    df = pd.DataFrame(hurdat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Beautify the Dataframe (Rename, Strip, Retype)\n",
    "\n",
    "Make the dataframe easier to work with by cleaning it up in several ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \"\"\" rename columns from HURDAT file, see note (1); returns given dataframe \"\"\"\n",
    "    # note we are leaving the storm radii columns (index 10-21) alone for now, we will deal with those later\n",
    "    col_names = {\n",
    "        df.columns[0]: 'Storm_Identifier',\n",
    "        df.columns[1]: 'Storm_Name',  \n",
    "        df.columns[2]: 'Date',\n",
    "        df.columns[3]: 'Time', \n",
    "        df.columns[4]: 'Record',\n",
    "        df.columns[5]: 'Status',\n",
    "        df.columns[6]: 'Lat',  \n",
    "        df.columns[7]: 'Lon',   \n",
    "        df.columns[8]: 'Wind',\n",
    "        df.columns[9]: 'Pressure'\n",
    "    }\n",
    "    df = df.rename(columns = col_names) # rename columns according to dictionary\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_string_columns(df):\n",
    "    \"\"\" Strip extra spaces on all object columns from raw HURDAT file; returns given dataframe \"\"\"\n",
    "    df_obj = df.select_dtypes(['object'])\n",
    "    df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip()) # strip spaces from string columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retype_columns(df):\n",
    "    \"\"\" convert column types into something more useful; returns given dataframe \"\"\"\n",
    "    df[['Wind','Pressure']] = df[['Wind','Pressure']].astype(str).astype(int) # convert from string to integer\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HURDAT stores Date and Time seperately, but combining them into one datetime column makes life soo much better ðŸ˜œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datetime_column(df):\n",
    "    \"\"\"\n",
    "    HURDAT data stores date and time in seperate columns, but we combine into one DateTime;\n",
    "    removes seperate date and time columns; returns given dataframe;\n",
    "    \"\"\"\n",
    "    df[\"DateTime\"] = df[\"Date\"] + ' ' + df[\"Time\"] # combine string columns\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"], format = '%Y%m%d %H%M') # convert to datetime object\n",
    "    df['YearDay'] = df.apply(lambda row: row.DateTime.timetuple().tm_yday, axis=1) # day of the year\n",
    "    df = df.drop(columns=['Date', 'Time'], axis=1) # remove unneeded columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Convert coordinates from string (19.7W) to float (-19.7)\n",
    "\n",
    "R (and others) understand much coordinates better as numbers instead of text, so we convert the string coordinates to numerics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coordinates(df):\n",
    "    \"\"\"\n",
    "    convert HURDAT string coordinates to something more useable (float between -180 and 180); \n",
    "    string coords have number and direction, so we split and multiply by -1 depending on hemisphere;\n",
    "    returns given dataframe\n",
    "    \"\"\"\n",
    "    for direc in ['Lat','Lon']: # loop for both coordinate types\n",
    "        # get the corrdiante's direction string (N,E,S,W) and numeric value\n",
    "        df[f'{direc}_Hemisphere'] = df[f'{direc}'].str[-1:]\n",
    "        df[f'{direc}'] = df[f'{direc}'].str[:-1].astype(float)\n",
    "        \n",
    "        # function to multiply value depending on direction string\n",
    "        convert_direc = lambda row: row[f\"{direc}\"]*-1 if row[f\"{direc}_Hemisphere\"] in ['S','W'] else row[f\"{direc}\"]\n",
    "        \n",
    "        # apply lambda func to get final numeric coordinate\n",
    "        df[f'{direc}'] = df.apply(convert_direc, axis=1)\n",
    "        \n",
    "        # remove old coordinate column\n",
    "        df = df.drop(columns=[f\"{direc}_Hemisphere\"]) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Wind Speed Acceleration\n",
    "\n",
    "The `Acceleration` column gives the average acceleration of wind speed (in kts/hr) since the last observation. \n",
    "\n",
    "For example: If Storm X has a wind speed of 100 kts at 1200 and increased to 120 kts at 1800, it would have an average acceleration of 20/6 = 3.333 kts/hr.\n",
    "\n",
    "Note: This calculation is made difficult by the sometimes inconsistent interval between observations. Observations usually come every 6 hours, but if the storm makes landfall inbetween, there will be a new observation at that time. In theory, I could remove observations not on the 6-hour but I don't want to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_hours(dt1,dt2):\n",
    "    \"\"\"\n",
    "    calculate the difference between two datetimes in hours, copied from stack; \n",
    "    args: dt1 (datetime), dt2 (datetime); returns: hours between dt1 and dt2;\n",
    "    \"\"\"\n",
    "    difference = dt1 - dt2 # get difference in datetime format\n",
    "    days, seconds = difference.days, difference.seconds # extract days and seconds bc hours is not native(??)\n",
    "    hours = days * 24 + seconds // 3600 # calculate hours\n",
    "    return hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acceleration(delta_wind, delta_time):\n",
    "    \"\"\"\n",
    "    calculate the acceleration per hour for a single strom interval;\n",
    "    args: \n",
    "        delta_wind (float): the change in wind in an interval\n",
    "        delta_time (float): the length in hours of the interval\n",
    "    returns: acceleration per hour (float) of wind during the interval\n",
    "    \"\"\"\n",
    "    try:\n",
    "        accel = delta_wind/delta_time\n",
    "    except:\n",
    "        accel = 0 # if delta_time = 0, let acceleration = 0\n",
    "        \n",
    "    # a 25 mph change in one hour is far too high to be plausible, so return 0 in this case bc something went wrong\n",
    "    accel = accel if abs(accel) < 25 else 0\n",
    "    \n",
    "    return accel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acceleration_column(df):\n",
    "    \"\"\"\n",
    "    storm observations usually come every 6 hours, though not always. this method calculates the change in \n",
    "    acceleration since the last observation for that storm;\n",
    "    returns the given dataframe, with a new column for accleration\n",
    "    \"\"\"\n",
    "    df[f\"Acceleration\"] = 0 # set default acceleration to 0\n",
    "    storm_codes = df.Storm_Identifier.unique() # get all unique storms\n",
    "    \n",
    "    # iterate through each storm code, create a dataframe for each strom\n",
    "    for index_storm, storm in enumerate(storm_codes):\n",
    "        df_storm = df[df.Storm_Identifier == storm] # get strom specific df\n",
    "        current_wind = previous_wind = 0 # set default values to 0\n",
    "        first_index = np.inf; # reset index to high number\n",
    "        \n",
    "        # loop through each row of the storm df\n",
    "        for index_row, row in df_storm.iterrows():\n",
    "            # record index of first row in storm df, to get assigned 0 acceleration later\n",
    "            if index_row < first_index: first_index = index_row\n",
    "            try:\n",
    "                # get current weather values\n",
    "                current_wind = df.iloc[index_row]['Wind']\n",
    "                current_time = df.iloc[index_row]['DateTime']\n",
    "                \n",
    "                # get weather values for previous row\n",
    "                previous_wind = df.iloc[index_row-1]['Wind']\n",
    "                previous_time = df.iloc[index_row-1]['DateTime']\n",
    "                \n",
    "                # calculate change in time and wind, used to calculate accleration\n",
    "                delta_wind = current_wind - previous_wind\n",
    "                delta_time = difference_in_hours(current_time,previous_time)\n",
    "                acceleration = calculate_acceleration(delta_wind,delta_time)\n",
    "            except:\n",
    "                acceleration = 0 # if any of the above failed, then set acceleration to 0\n",
    "            df.loc[index_row,'Acceleration'] = acceleration # set acceleration in full dataframe\n",
    "        df.loc[first_index,'Acceleration'] = 0 # set acceleration of first row in storm df to 0\n",
    "        first_index = np.inf; # reset index of first row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Calculate Radii of High Intensity\n",
    "\n",
    "The last set of columns (the ones we ignored earlier) described the 'size' of the storm. Specifically, they give the maximum extent (in nautical miles) of a certain wind speed in one quadrant. Because twelve size variables is far many, we average these four quadrants together to get the average maximum extent of the three wind speeds, 34kt, 50kt, and 64 kts. This tells us the average radius of the storm with wind speeds above these marks, giving us three proxies for 'storm size'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wind_radii(df):\n",
    "    \"\"\"\n",
    "    calculate the average radius of different wind speed by average the wind extent in the four quadrants;\n",
    "    HURDAT data has extent of 34,50,64kt winds in 4 quadrants (NW,SW,SE,NE), we average them to just 3 numbers;\n",
    "    returns given dataframe, with 3 new columns for extent of 34,50,64kt winds\n",
    "    \"\"\"\n",
    "    # get average of 4 quadrant observations for 3 wind categories, and record as single column\n",
    "    df[\"34kt_radius\"] = df[[10,11,12,13]].astype(str).astype(int).mean(axis=1) \n",
    "    df[\"50kt_radius\"] = df[[14,15,16,17]].astype(str).astype(int).mean(axis=1)\n",
    "    df[\"64kt_radius\"] = df[[18,19,20,21]].astype(str).astype(int).mean(axis=1)\n",
    "    df.drop(columns = [10,11,12,13,14,15,16,17,18,19,20,21,22], inplace=True) # drop unneeded columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Calculate Bearing, Distance, and Storm Speed\n",
    "\n",
    "Create additional columns that may prove useful for the machine learning model, including:\n",
    "- Bearing: the bearing (direction) the storm is moving in (between -180 and 180)\n",
    "- Distance: the distance the storm has traveled since the last observation in nautical miles\n",
    "- Speed: the speed of the storm track (not wind speed) in knots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bearing_distance_speed_columns(df):\n",
    "    geodesic = pyproj.Geod(ellps='WGS84')\n",
    "    df[f\"Bearing\"] = 0 # set default bearing to 0\n",
    "    df[f\"Distance\"] = 0 # set default bearing to 0\n",
    "    df[f\"Speed\"] = 0 # set default bearing to 0\n",
    "    \n",
    "    storm_codes = df.Storm_Identifier.unique() # get all unique storms\n",
    "    # iterate through each storm code, create a dataframe for each strom\n",
    "    for index_storm, storm in enumerate(storm_codes):\n",
    "        df_storm = df[df.Storm_Identifier == storm] # get strom specific df\n",
    "        current_bearing = previous_bearing = 0 # set default values to 0\n",
    "        first_index = np.inf; # reset index to high number\n",
    "        \n",
    "        # loop through each row of the storm df\n",
    "        for index_row, row in df_storm.iterrows():\n",
    "            \n",
    "            # record index of first row in storm df, to get assigned 0 later\n",
    "            if index_row < first_index: \n",
    "                first_index = index_row\n",
    "                \n",
    "            try:\n",
    "                # calculate change in time since last obersvation\n",
    "                current_time = df.iloc[index_row]['DateTime']\n",
    "                previous_time = df.iloc[index_row-1]['DateTime']\n",
    "                delta_time = difference_in_hours(current_time,previous_time)\n",
    "                \n",
    "                # get current position\n",
    "                current_position = [df.iloc[index_row]['Lat'],df.iloc[index_row]['Lon']]\n",
    "                \n",
    "                # get previous position\n",
    "                previous_position = [df.iloc[index_row-1]['Lat'],df.iloc[index_row-1]['Lon']]\n",
    "                \n",
    "                # use geodesic to calculate bearing and distance between observations\n",
    "                bearing, back_bearing, distance = geodesic.inv(\n",
    "                    previous_position[1], previous_position[0], current_position[1], current_position[0])\n",
    "                \n",
    "                # calculate distance and speed in nautical miles\n",
    "                distance = distance/1852 # 1 nautical mile = 1852 meters\n",
    "                speed = distance / delta_time\n",
    "                \n",
    "            except:\n",
    "                # if any error occured, let all values equal 0\n",
    "                bearing = 0; distance = 0; speed = 0;\n",
    "                \n",
    "            # set the values for the current row\n",
    "            df.loc[index_row,'Bearing'] = bearing\n",
    "            df.loc[index_row,'Distance'] = distance\n",
    "            df.loc[index_row,'Speed'] = speed\n",
    "            \n",
    "        # set the values for the first row of storm\n",
    "        df.loc[first_index,'Bearing'] = 0\n",
    "        df.loc[first_index,'Distance'] = 0\n",
    "        df.loc[first_index,'Speed'] = 0\n",
    "        \n",
    "        # reset index of first row\n",
    "        first_index = np.inf; \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Add current storm category\n",
    "Create a variable denoting the storms current category based on the Saffir-Simpson Hurricane Wind Scale. If not a hurricane, assign Category 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_category(wind):\n",
    "    \"\"\"\n",
    "    args: wind speed; returns: storm category (0 to 5) based on the given wind speed\n",
    "    \"\"\"\n",
    "    cat_breaks = [64,83,96,113,137,300]\n",
    "    for i,cat in enumerate(cat_breaks):\n",
    "        if wind > 0 and wind < cat:\n",
    "            return i\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category_column(df):\n",
    "    \"\"\"\n",
    "    add column to dataframe denoting the current hurricane category of the storm; returns given dataframe;\n",
    "    \"\"\"\n",
    "    df['Category'] = df.apply(lambda row: calculate_category(row.Wind), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Remove storms that do not reach Category X\n",
    "\n",
    "Not all storms in HURDAT dataset are hurricanes, there are also distrubrances, waves, tropical storms and more. In fact, more than half of the storms do not reach the 64kt barrier to be classified as a Category 1 hurricane. Beyond that, only 1/3 of all hurricanes are considered 'major', making it to category 3, 4 or 5.\n",
    "\n",
    "This method removes storms from the dataframe if they do not reach the given category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_storms_below_cat_X(df, X):\n",
    "    \"\"\"\n",
    "    remove storms from the full dataset if the storm did not reach category X;\n",
    "    args: df: full strom df, X (int): remove stroms if they do not meet category X\n",
    "    \"\"\"\n",
    "    if X not in range(1,6): return df # if not a valid storm category, retrun the full df\n",
    "    \n",
    "    # minimum wind speed for each category hurricane\n",
    "    cat_X_minimum_wind_speeds = {1:64 , 2:83, 3:96, 4:113, 5:137} \n",
    "    \n",
    "    # compare max wind speed of strom with desired category miniumum, remove storm if it does not reach threshold\n",
    "    df = df[(df.groupby('Storm_Identifier')['Wind'].transform('max')) >= cat_X_minimum_wind_speeds[X]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Create `Rapid_NHC24` column\n",
    "\n",
    "This column will denote whether a storm was Rapid Increasing (per NHC, defined as an increase of 30 knots in maximum sustained wind speed over the previous 24 hours) at the time of the observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_k_hours_before(time, series, k):\n",
    "    \"\"\"\n",
    "    get items in series whose datetime is within k before hours of argument time;\n",
    "    args: time (datetime), series (series) of HURDAT observations;\n",
    "    return: series with items whose datetime is within k hours before of the argument time\n",
    "    \"\"\"\n",
    "    return (time-timedelta(hours=k) <= series) & (series <= time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def within_k_hours_after(time, series, k):\n",
    "    \"\"\"\n",
    "    get items in series whose datetime is within k after hours of argument time;\n",
    "    args: time (datetime), series (series) of HURDAT observations;\n",
    "    return: series with items whose datetime is within k hours after of the argument time\n",
    "    \"\"\"\n",
    "    return (time <= series) & (series <= time+timedelta(hours=k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rapid_NHC24_column(df):\n",
    "    \"\"\"\n",
    "    create boolean column based on if storm was 'Rapidly Increasing' per NHC defn. at the time of the observation;\n",
    "    returns given dataframe of strom observations;\n",
    "    \"\"\"\n",
    "    storm_codes = df.Storm_Identifier.unique() # list of unique stroms\n",
    "    for index_storm, storm in enumerate(storm_codes): # iterate through all stroms \n",
    "        df_storm = df[df.Storm_Identifier == storm] # get df for each storm\n",
    "        for index_row, row in df_storm.iterrows():\n",
    "            # get current time and wind for the row\n",
    "            current_time = row['DateTime']; \n",
    "            current_wind = row[\"Wind\"] \n",
    "\n",
    "            # find all observations within 24 hours of current observation\n",
    "            df_k_hours_before = df_storm[ within_k_hours_before(current_time, df_storm['DateTime'], 24) ]\n",
    "\n",
    "            # get minimum wind within k hours\n",
    "            min_wind_k_hours = df_k_hours_before[\"Wind\"].min() \n",
    "\n",
    "            # determine if strom was RI if it increased by 30mph in the last k hours\n",
    "            df.loc[index_row,f\"Rapid_NHC24\"] = (current_wind - min_wind_k_hours ) > 30 \n",
    "          \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Create Outcome Variables for Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create several different outcome variable to used in different machine learning models later in the analysis.\n",
    "1. `Outcome_Total`: this variable denotes whether the storm will rapidly increase in the next 24 hours\n",
    "2. `Outcome_Switch`: this variable denotes whether the storm will switch from non-rapidly increasing to rapidly increasing in the next 24 hours\n",
    "3. `Outcome_HoursToRapid`: this variable denoted the number of hours until the storm will be rapidly increasing. If the storm does not become rapidly increasing after that observation, the varible is assigned NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outcome_columns(df):\n",
    "    \"\"\"\n",
    "    creates the outcome variables used in the machine learning models later on; \n",
    "    three outcome variables are created and described in the text above;\n",
    "    returns given dataframe with three new columns: Outcome_Total, Outcome_Switch, and Outcome_HoursToRapid\n",
    "    \"\"\"\n",
    "    storm_codes = df.Storm_Identifier.unique() # list of unique stroms\n",
    "    for storm in storm_codes: # iterate through all stroms \n",
    "        df_storm = df[df.Storm_Identifier == storm] # get df for each storm\n",
    "        \n",
    "        for index_row, row in df_storm.iterrows():\n",
    "            # get current time and RI status of observation\n",
    "            current_time = row['DateTime'];\n",
    "            current_status = row[f\"Rapid_NHC24\"]\n",
    "            \n",
    "            # create dataframe with all observatinos within 24 hours after the current one\n",
    "            df_24_hours_after = (df_storm[ within_k_hours_after(current_time, df_storm['DateTime'], 24) ])\n",
    "            \n",
    "            # calculate outcome variables, see above\n",
    "            df.loc[index_row, \"Outcome_Total\"] = True in df_24_hours_after[f'Rapid_NHC24'].tolist()\n",
    "            df.loc[index_row, \"Outcome_Switch\"] = (not current_status and True in df_24_hours_after[f'Rapid_NHC24'].tolist())\n",
    "            \n",
    "            # not efficient but someone the only effective method\n",
    "            for k in range(600,-1,-6):\n",
    "                # get dataframe with all observations with k hours of the current one\n",
    "                df_k_hours_after = (df_storm[ within_k_hours_after(current_time, df_storm['DateTime'], k) ])\n",
    "                \n",
    "                # if any observations in the dataframe are rapidly intensifying, change outcome column to k\n",
    "                if (True in df_k_hours_after[f'Rapid_NHC24'].tolist()):\n",
    "                    df.loc[index_row, \"Outcome_HoursToRapid\"] = k  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "lines = read_hurdat_lines()\n",
    "df = hurdat_lines_to_df(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up dataframe\n",
    "df = rename_columns(df)\n",
    "df = strip_string_columns(df)\n",
    "df = create_datetime_column(df)\n",
    "df = retype_columns(df)\n",
    "\n",
    "# Create new columns from calculations\n",
    "df = create_acceleration_column(df)\n",
    "df = convert_coordinates(df)\n",
    "df = create_bearing_distance_speed_columns(df)\n",
    "df = create_category_column(df)\n",
    "df = calculate_wind_radii(df)\n",
    "df = create_rapid_NHC24_column(df)\n",
    "df = create_outcome_columns(df)\n",
    "\n",
    "# Remove unneeded stroms\n",
    "# df = remove_storms_below_cat_X(df,1)\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "# Create Pickle\n",
    "d = datetime.today()\n",
    "df.to_pickle(f\"{d.month}_{d.day}_{d.year}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Storm_Identifier</th>\n",
       "      <th>Storm_Name</th>\n",
       "      <th>Record</th>\n",
       "      <th>Status</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>YearDay</th>\n",
       "      <th>...</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Category</th>\n",
       "      <th>34kt_radius</th>\n",
       "      <th>50kt_radius</th>\n",
       "      <th>64kt_radius</th>\n",
       "      <th>Rapid_NHC24</th>\n",
       "      <th>Outcome_Total</th>\n",
       "      <th>Outcome_Switch</th>\n",
       "      <th>Outcome_HoursToRapid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-94.8</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "      <td>1851-06-25 00:00:00</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-95.4</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "      <td>1851-06-25 06:00:00</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>31.866664</td>\n",
       "      <td>5.311111</td>\n",
       "      <td>1</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "      <td>1851-06-25 12:00:00</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>31.866664</td>\n",
       "      <td>5.311111</td>\n",
       "      <td>1</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.1</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "      <td>1851-06-25 18:00:00</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>27.209413</td>\n",
       "      <td>4.534902</td>\n",
       "      <td>1</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>L</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>80</td>\n",
       "      <td>-999</td>\n",
       "      <td>1851-06-25 21:00:00</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>16.999238</td>\n",
       "      <td>5.666413</td>\n",
       "      <td>1</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52712</th>\n",
       "      <td>AL312020</td>\n",
       "      <td>IOTA</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-84.7</td>\n",
       "      <td>75</td>\n",
       "      <td>965</td>\n",
       "      <td>2020-11-17 12:00:00</td>\n",
       "      <td>322</td>\n",
       "      <td>...</td>\n",
       "      <td>52.567679</td>\n",
       "      <td>8.761280</td>\n",
       "      <td>1</td>\n",
       "      <td>122.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52713</th>\n",
       "      <td>AL312020</td>\n",
       "      <td>IOTA</td>\n",
       "      <td></td>\n",
       "      <td>TS</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-85.7</td>\n",
       "      <td>55</td>\n",
       "      <td>988</td>\n",
       "      <td>2020-11-17 18:00:00</td>\n",
       "      <td>322</td>\n",
       "      <td>...</td>\n",
       "      <td>58.408525</td>\n",
       "      <td>9.734754</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52714</th>\n",
       "      <td>AL312020</td>\n",
       "      <td>IOTA</td>\n",
       "      <td></td>\n",
       "      <td>TS</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-86.7</td>\n",
       "      <td>40</td>\n",
       "      <td>1000</td>\n",
       "      <td>2020-11-18 00:00:00</td>\n",
       "      <td>323</td>\n",
       "      <td>...</td>\n",
       "      <td>58.700917</td>\n",
       "      <td>9.783486</td>\n",
       "      <td>0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52715</th>\n",
       "      <td>AL312020</td>\n",
       "      <td>IOTA</td>\n",
       "      <td></td>\n",
       "      <td>TS</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-87.8</td>\n",
       "      <td>35</td>\n",
       "      <td>1005</td>\n",
       "      <td>2020-11-18 06:00:00</td>\n",
       "      <td>323</td>\n",
       "      <td>...</td>\n",
       "      <td>64.222106</td>\n",
       "      <td>10.703684</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52716</th>\n",
       "      <td>AL312020</td>\n",
       "      <td>IOTA</td>\n",
       "      <td></td>\n",
       "      <td>TD</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1006</td>\n",
       "      <td>2020-11-18 12:00:00</td>\n",
       "      <td>323</td>\n",
       "      <td>...</td>\n",
       "      <td>70.329531</td>\n",
       "      <td>11.721589</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52717 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Storm_Identifier Storm_Name Record Status   Lat   Lon  Wind  Pressure  \\\n",
       "0             AL011851    UNNAMED            HU  28.0 -94.8    80      -999   \n",
       "1             AL011851    UNNAMED            HU  28.0 -95.4    80      -999   \n",
       "2             AL011851    UNNAMED            HU  28.0 -96.0    80      -999   \n",
       "3             AL011851    UNNAMED            HU  28.1 -96.5    80      -999   \n",
       "4             AL011851    UNNAMED      L     HU  28.2 -96.8    80      -999   \n",
       "...                ...        ...    ...    ...   ...   ...   ...       ...   \n",
       "52712         AL312020       IOTA            HU  13.7 -84.7    75       965   \n",
       "52713         AL312020       IOTA            TS  13.7 -85.7    55       988   \n",
       "52714         AL312020       IOTA            TS  13.8 -86.7    40      1000   \n",
       "52715         AL312020       IOTA            TS  13.8 -87.8    35      1005   \n",
       "52716         AL312020       IOTA            TD  13.7 -89.0    25      1006   \n",
       "\n",
       "                 DateTime  YearDay  ...   Distance      Speed  Category  \\\n",
       "0     1851-06-25 00:00:00      176  ...   0.000000   0.000000         1   \n",
       "1     1851-06-25 06:00:00      176  ...  31.866664   5.311111         1   \n",
       "2     1851-06-25 12:00:00      176  ...  31.866664   5.311111         1   \n",
       "3     1851-06-25 18:00:00      176  ...  27.209413   4.534902         1   \n",
       "4     1851-06-25 21:00:00      176  ...  16.999238   5.666413         1   \n",
       "...                   ...      ...  ...        ...        ...       ...   \n",
       "52712 2020-11-17 12:00:00      322  ...  52.567679   8.761280         1   \n",
       "52713 2020-11-17 18:00:00      322  ...  58.408525   9.734754         0   \n",
       "52714 2020-11-18 00:00:00      323  ...  58.700917   9.783486         0   \n",
       "52715 2020-11-18 06:00:00      323  ...  64.222106  10.703684         0   \n",
       "52716 2020-11-18 12:00:00      323  ...  70.329531  11.721589         0   \n",
       "\n",
       "       34kt_radius  50kt_radius  64kt_radius  Rapid_NHC24  Outcome_Total  \\\n",
       "0           -999.0       -999.0       -999.0        False          False   \n",
       "1           -999.0       -999.0       -999.0        False          False   \n",
       "2           -999.0       -999.0       -999.0        False          False   \n",
       "3           -999.0       -999.0       -999.0        False          False   \n",
       "4           -999.0       -999.0       -999.0        False          False   \n",
       "...            ...          ...          ...          ...            ...   \n",
       "52712        122.5         37.5         12.5        False          False   \n",
       "52713         90.0         15.0          0.0        False          False   \n",
       "52714         67.5          0.0          0.0        False          False   \n",
       "52715         35.0          0.0          0.0        False          False   \n",
       "52716          0.0          0.0          0.0        False          False   \n",
       "\n",
       "      Outcome_Switch Outcome_HoursToRapid  \n",
       "0              False                  NaN  \n",
       "1              False                  NaN  \n",
       "2              False                  NaN  \n",
       "3              False                  NaN  \n",
       "4              False                  NaN  \n",
       "...              ...                  ...  \n",
       "52712          False                  NaN  \n",
       "52713          False                  NaN  \n",
       "52714          False                  NaN  \n",
       "52715          False                  NaN  \n",
       "52716          False                  NaN  \n",
       "\n",
       "[52717 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"12_15_2021.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note 1: The format of the NHC HURDAT2.csv file\n",
    "\n",
    "[From NHC] This dataset (known as Atlantic HURDAT2) is provided in comma-delimited, text format with six-hourly information on the location, maximum winds, central pressure, and (beginning in 2004) size of all known tropical cyclones and subtropical cyclones.\n",
    "\n",
    "The format of the HURDAT file looks like this:\n",
    "\n",
    "- **Storm Idenifier Row**\n",
    "- *Strom Observation Row*\n",
    "- *Strom Observation Row*\n",
    "- *Strom Observation Row*\n",
    "- **Storm Idenifier Row**\n",
    "- *Strom Observation Row*\n",
    "- *Strom Observation Row*\n",
    "- *Strom Observation Row*\n",
    "- *Strom Observation Row*\n",
    "\n",
    "#### Important!\n",
    "Within in an observation row, there is nothing that can identify which storm that the row belongs to. Thus, we need to add a storm identifier to each row for ease of use later. We do this in the `hurdat_lines_to_df` method below. \n",
    "\n",
    "See an example of the unchanged HURDAT data from Hurricane Irene below:\n",
    "\n",
    "`AL092011,  IRENE,  39,  \n",
    "20110821, 0000,  , TS, 15.0N,  59.0W,  45, 1006,  105, 0, 0,45, 0, 0, 0, 0, 0, 0, 0, 0,  \n",
    "20110821, 0600,  , TS, 16.0N,  60.6W,  45, 1006,  130, 0, 0,80, 0, 0, 0, 0, 0, 0, 0, 0,  \n",
    "20110821, 1200,  , TS, 16.8N,  62.2W,  45, 1005,  130, 0, 0,70, 0, 0, 0, 0, 0, 0, 0, 0,  \n",
    "20110821, 1800,  , TS, 17.5N,  63.7W,  50,  999,  130,20, 0,70,30, 0, 0, 0, 0, 0, 0, 0,  \n",
    "20110822, 0000,  , TS, 17.9N,  65.0W,  60,  993,  130,30,30,90,30, 0, 0,30, 0, 0, 0, 0,  \n",
    "20110822, 0600,  , HU, 18.2N,  65.9W,  65,  990,  130,60,60,90,40,25,20,35,25, 0, 0, 0,  \n",
    "20110822, 1200,  , HU, 18.9N,  67.0W,  70,  989,  160,60,60,90,40,25,20,35,25, 0, 0, 0,  \n",
    "20110822, 1800,  , HU, 19.3N,  68.0W,  75,  988,  160,60,40,90,40,30,20,35,25, 0, 0, 0, `\n",
    "\n",
    "The columns of the HURDAT file are as follows, refer to the link for more details.\n",
    "- Date (YYYYMMDD)\n",
    "- Time (24 hr)\n",
    "- Record Identifier (see link for more info)\n",
    "- Storm Status (Tropical Storm, Hurricane, etc. see link for more info)\n",
    "- Latitude\n",
    "- Longitude\n",
    "- Maximum Sustained Wind Speed (kts)\n",
    "- Minimum Pressure (mbar)\n",
    "- 34 kt wind radii maximum extent in NE quadrant (in nautical miles)\n",
    "- 34 kt wind radii maximum extent in SE quadrant (in nautical miles)\n",
    "- 34 kt wind radii maximum extent in SW quadrant (in nautical miles)\n",
    "- 34 kt wind radii maximum extent in NW quadrant (in nautical miles)\n",
    "- 50 kt wind radii maximum extent in NE quadrant (in nautical miles)\n",
    "- 50 kt wind radii maximum extent in SE quadrant (in nautical miles)\n",
    "- 50 kt wind radii maximum extent in SW quadrant (in nautical miles)\n",
    "- 50 kt wind radii maximum extent in NW quadrant (in nautical miles)\n",
    "- 64 kt wind radii maximum extent in NE quadrant (in nautical miles)\n",
    "- 64 kt wind radii maximum extent in SE quadrant (in nautical miles)\n",
    "- 64 kt wind radii maximum extent in SW quadrant (in nautical miles)\n",
    "- 64 kt wind radii maximum extent in NW quadrant (in nautical miles)\n",
    "\n",
    "To learn more about the format of the HURDAT2 file, see the description at https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-nov2019.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
